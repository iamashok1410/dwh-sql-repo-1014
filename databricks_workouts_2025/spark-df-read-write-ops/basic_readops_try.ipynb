{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe8dec54-2208-4948-b400-d83073964bd9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "create catalog if not exists catalog1_dropme;\n",
    "create database if not exists catalog1_dropme.schema1_dropme;\n",
    "create volume if not exists catalog1_dropme.schema1_dropme.volume1_dropme;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc656e60-2e1d-4309-8416-15dc3410e598",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.mkdirs(\"/Volumes/catalog1_dropme/schema1_dropme/volume1_dropme/directory_dropme\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77151497-0a73-4f64-bc46-ede48df37278",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.session import SparkSession\n",
    "print(spark)\n",
    "spark1=SparkSession.builder.getOrCreate()\n",
    "print(spark1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4721fec4-d558-402e-8793-af45f92616ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Create a DBFS volume namely commondata and upload the above data in that volume What are other FS uri's available? file:///, hdfs:///, dbfs:///, gs:///, s3:///, adls:///, blob:///"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "247e1c24-468d-4ea4-8f4e-091ae8d86921",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "csv_df1=spark.read.csv(\"dbfs:///Volumes/catalog1_dropme/schema1_dropme/volume1_dropme/directory_dropme/custs\")\n",
    "display(csv_df1)\n",
    "print(csv_df1.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "412495d3-9590-49af-97fe-cb2bf7833267",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "csv_df1=spark.read.csv(\"/Volumes/catalog1_dropme/schema1_dropme/volume1_dropme/directory_dropme/custs_header\",header=True)\n",
    "print(csv_df1.printSchema())\n",
    "csv_df1.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a76ce4e6-434a-4c07-ad0c-9d7d707f32a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "csv_df2=spark.read.csv(\"/Volumes/catalog1_dropme/schema1_dropme/volume1_dropme/directory_dropme/custs\").toDF(\"id\",\"fname\",\"lname\",\"age\",\"prof\")\n",
    "csv_df2.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98a14a29-b2f4-4ddf-8ffc-9b39b0854e1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_multiple_sources=spark.read.csv(path=[\"/Volumes/catalog1_dropme/schema1_dropme/volume1_dropme/directory_dropme/custsmodified_NY\",\"dbfs:////Volumes/catalog1_dropme/schema1_dropme/volume1_dropme/directory_dropme/custsmodified_TX\"],inferSchema=True,header=True,sep=',',pathGlobFilter=\"custs_header_*\",recursiveFileLookup=True)\n",
    "#.toDF(\"cid\",\"fn\",\"ln\",\"a\",\"p\")\n",
    "print(df_multiple_sources.count())\n",
    "df_multiple_sources.show(2)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7516792023160098,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "basic_readops_try",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
